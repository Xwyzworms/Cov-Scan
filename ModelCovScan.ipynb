{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aggregate-temperature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas Version 1.1.5\n",
      "Numpy version 1.19.2\n",
      "Tensorflow Version 2.1.0\n",
      "CV Version 4.5.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from matplotlib.image import imread\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "print(\"Pandas Version %s\" %pd.__version__)\n",
    "print(\"Numpy version %s\" % np.__version__)\n",
    "print(\"Tensorflow Version %s\" % tf.__version__)\n",
    "print(\"CV Version %s\" % cv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-plant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "touched-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessImage(image):\n",
    "    image = image / 255.0 \n",
    "    image = cv.resize(image,(400,400))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "indirect-label",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Covid  460\n",
      "Train normal 1266\n",
      "Train Pneumonia 3418\n",
      "Test Covid 116\n",
      "Test Normal 317\n",
      "Test PneuMonia 855\n",
      "Test Covid 100\n",
      "Test Non covid 100\n",
      "Train covid 1252\n",
      "Train Non Covid 1229\n"
     ]
    }
   ],
   "source": [
    "# Take A look To data\n",
    "print(\"Train Covid \" ,len(os.listdir(\"Data/DataSetXray/train/COVID19/\")))\n",
    "print(\"Train normal\", len(os.listdir(\"Data/DataSetXray/train/NORMAL//\")))\n",
    "print(\"Train Pneumonia\", len(os.listdir(\"Data/DataSetXray/train/PNEUMONIA//\")))\n",
    "\n",
    "\n",
    "print(\"Test Covid\", len(os.listdir(\"Data/DataSetXray/test/COVID19/\")))\n",
    "print(\"Test Normal\", len(os.listdir(\"Data/DataSetXray/test/NORMAL//\")))\n",
    "print(\"Test PneuMonia\" ,len(os.listdir(\"Data/DataSetXray/test/PNEUMONIA//\")))\n",
    "\n",
    "print(\"Test Covid\" ,len(os.listdir(\"Data/DataSetCT/test/covid/\")))\n",
    "print(\"Test Non covid\" ,len(os.listdir(\"Data/DataSetCT/test/noncovid//\")))\n",
    "print(\"Train covid\" ,len(os.listdir(\"Data/DataSetCT/train/covid/\")))\n",
    "print(\"Train Non Covid\", len(os.listdir(\"Data/DataSetCT/train/noncovid//\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "arranged-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAININGXRAY = \"Data/DataSetXray/train/\"\n",
    "TESTXRAY = \"Data/DataSetXray/test/\"\n",
    "\n",
    "TRAININGCT = \"Data/DataSetCT/train/\"\n",
    "TESTCT = \"Data/DataSetCT/test/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "olympic-literature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5144 images belonging to 3 classes.\n",
      "Found 1288 images belonging to 3 classes.\n",
      "Found 2481 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trainXrayDatagen = ImageDataGenerator(rescale=1./255,\n",
    "                                     rotation_range=40,\n",
    "                                     width_shift_range=0.2,\n",
    "                                     height_shift_range=0.2,\n",
    "                                     shear_range=0.2,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True,\n",
    "                                     fill_mode=\"nearest\")\n",
    "\n",
    "trainXrayGenerator = trainXrayDatagen.flow_from_directory(TRAININGXRAY,\n",
    "                                                         batch_size=32,\n",
    "                                                         class_mode=\"categorical\",\n",
    "                                                         target_size=(150,150))\n",
    "\n",
    "testXrayDatagen = ImageDataGenerator(rescale=1./255,)\n",
    "testXrayGenerator = testXrayDatagen.flow_from_directory(TESTXRAY,\n",
    "                                                       batch_size=32,\n",
    "                                                       class_mode=\"categorical\",\n",
    "                                                       target_size=(150,150))\n",
    "\n",
    "trainCtDatagen = ImageDataGenerator(rescale=  1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range= 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode=\"nearest\")\n",
    "trainCtGenerator = trainCtDatagen.flow_from_directory(TRAININGCT,\n",
    "                                                     batch_size=32,\n",
    "                                                     class_mode=\"binary\",\n",
    "                                                     target_size=(150,150))\n",
    "testCtDatagen = ImageDataGenerator(rescale=1./255)\n",
    "testCtGenerator = testCtDatagen.flow_from_directory(TESTCT,\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode=\"binary\",\n",
    "                                                   target_size=(150,150))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-lambda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 161 steps, validate for 41 steps\n",
      " 15/161 [=>............................] - ETA: 9:39 - loss: 0.9437 - acc: 0.6521"
     ]
    }
   ],
   "source": [
    "# Creating Model For Both using modeSubclassing\n",
    "class XrayModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, filters =  64, kernel_size = 7):\n",
    "        super(XrayModel,self).__init__()\n",
    "        \n",
    "        self.convolution = tf.keras.layers.Conv2D(filters,kernel_size=kernel_size,padding=\"SAME\")\n",
    "        self.maxPooling = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.batchNormalization = tf.keras.layers.BatchNormalization()\n",
    "        self.convolution2 = tf.keras.layers.Conv2D( filters, (3,3), padding= \"SAME\")\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.globalAvgPooling = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(1024, activation=tf.nn.relu)\n",
    "        self.outputLayer = tf.keras.layers.Dense(3, activation = tf.nn.softmax)\n",
    "        \n",
    "    def call(self, input_tensors):\n",
    "        \n",
    "        layers = self.convolution(input_tensors)\n",
    "        layers = self.relu(layers)\n",
    "        layers = self.maxPooling(layers)\n",
    "        layers = self.batchNormalization(layers)\n",
    "        layers = self.globalAvgPooling(layers)\n",
    "        \n",
    "        layers2 = self.convolution2(input_tensors)\n",
    "        layers2 = self.relu(layers2)\n",
    "        layers2 = self.maxPooling(layers2)\n",
    "        layers2 = self.batchNormalization(layers2)\n",
    "        layers2 = self.globalAvgPooling(layers2)\n",
    "        \n",
    "        finLayer = self.concat([layers,layers2])\n",
    "\n",
    "        dense = self.dense(finLayer)\n",
    "        output = self.outputLayer(dense)\n",
    "        \n",
    "        return output\n",
    "xrayModel = XrayModel() \n",
    "xrayModel.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                 loss =\"categorical_crossentropy\", \n",
    "                 metrics=[\"acc\"])\n",
    "\n",
    "xrayModel.fit(trainXrayGenerator,validation_data=testXrayGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "continuous-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating ResNet Architecthure But not going to use it :\n",
    "\n",
    "class identityBlockOne(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, filters : int, kernel_size : int):\n",
    "        super(identityBlockOne,self).__init__()\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters,kernel_size,padding=\"SAME\")\n",
    "        self.batchNorm1 = tf.keras.layers.BatchNormalization()\n",
    "        self.pooling1 = tf.keras.layers.MaxPool2D((3,3),padding=\"same\")\n",
    "    \n",
    "        self.activation = tf.keras.layers.Activation(tf.nn.relu)\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        \n",
    "    def call (self, input_tensors):\n",
    "        \n",
    "        layer = self.conv1(input_tensors)\n",
    "        for i in range(2):\n",
    "            layer = self.conv1(layer)\n",
    "            layer = self.activation(layer)\n",
    "            layer = self.batchNorm1(layer)\n",
    "\n",
    "        layer = self.add([layer,input_tensors])\n",
    "        layer = self.activation(layer)\n",
    "        return layer\n",
    "    \n",
    "class identityBlockTwo(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super(identityBlockTwo,self).__init__()\n",
    "        self.amountLoop = 5\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters,kernel_size,padding=\"SAME\")\n",
    "        self.activation = tf.keras.layers.Activation(tf.nn.relu)\n",
    "        self.pooling = tf.keras.layers.MaxPool2D((3,3))\n",
    "        self.batchNormalization = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters,kernel_size)\n",
    "        self.add = tf.keras.layers.Add()\n",
    "    \n",
    "    def call (self, input_tensors):\n",
    "\n",
    "        layer = self.conv1(input_tensors)\n",
    "        layer = self.activation(layer)\n",
    "        layer = self.batchNormalization(layer)\n",
    "        \n",
    "        for i in range(self.amountLoop):\n",
    "            layer = self.conv1(layer)\n",
    "            layer = self.activation(layer)\n",
    "            layer = self.batchNormalization(layer)\n",
    "            \n",
    "        layer = self.add([layer,input_tensors])\n",
    "        layer = self.activation(layer)\n",
    "        \n",
    "        return layer\n",
    "\n",
    "\n",
    "class ResNet(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet,self).__init__()\n",
    "        \n",
    "        self.conv = tf.keras.layers.Conv2D(64, 7, padding=\"SAME\")\n",
    "        self.batchNormalization = tf.keras.layers.BatchNormalization()\n",
    "        self.activation = tf.keras.layers.Activation(tf.nn.relu)\n",
    "        self.max_pool = tf.keras.layers.MaxPool2D((3,3))\n",
    "        \n",
    "        self.id1 = identityBlockOne(64, 5)\n",
    "        self.id2 = identityBlockTwo(64 ,5)\n",
    "        \n",
    "        self.global_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.classifier = tf.keras.layers.Dense(num_classes, activation = tf.nn.softmax)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        x = self.batchNormalization(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        x = self.id1(x)\n",
    "        for i in range(0,3):\n",
    "            x = self.id2(x)\n",
    "        \n",
    "        x = self.global_pool(x)\n",
    "        \n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "measured-repository",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1807/Unknown - 1347s 746ms/step - loss: 0.1578 - accuracy: 0.9525"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-723c32bf217f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestPreprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def testPreprocess(features):\n",
    "    return tf.cast(features[\"image\"], tf.float32)/ 255, features['label'] \n",
    "resnet = ResNet(10)\n",
    "resnet.compile('adam',loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "dataset = tfds.load('mnist',split=tfds.Split.TRAIN)\n",
    "dataset = dataset.map(testPreprocess).batch(32)\n",
    "\n",
    "history = resnet.fit(dataset,epochs=1)\n",
    "print(history.history[\"accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
